#非监督学习
[K均值聚类](#K均值聚类)

## K均值聚类: K mean clustering:
1.  基本思想：通过迭代的方法寻找K个cluster, 使得聚类的结果对应的cost最小。最简单的cost就是各个样本距离其簇中心的误差平方和。
2.  基本步骤：
    1.  数据预处理：归一化，离群点处理
    2.  随机选取k个簇中心，不一定是data的点
    3.  计算cost =
    4.  对每个样本计算其到 K个簇中心的距离并由此判断其属于哪一个簇
    5.  对每个簇，重新计算当前的簇的中心
    6.  重复步骤3 - 5 直至cost收敛
3.  优缺点：
    1.  缺点：
        1.  分簇的结果收到初始的预设的簇中心影响较大，
        2.  簇中心收到离群点的影响较大：因为可能一个离群点会导致中心偏离
        3.  由于1、2，经常导致每次的结果都不稳定从而出现局部最优解的情况
        4.  无法解决簇样本数量相差较大的情况，例如一个是另一个的100被的话就是导致cost的计算出现问题
    2.  优点：
        1.  计算复杂度是O(NKt): N:数据量，K:簇数量，t:iteration次数
        2.  虽然经常以局部最优结束，但是一般情况下能达到局部最优就可以
4.  优化：
    1.  数据预处理：归一化以及离群点的处理
    2.  合理选择K的值：plot K 与 最后的cost之间的关系。
        1.  一般认为拐点处的K值就是最好的选择。但是需要人工干预不能自动化
        2.  Gap Statics: 自动化的选择K值
    3.  加入核函数：
        1.  因为欧式距离往往不是最好的选择。它最后只会形成一个球型，而这往往不是最好的情况。
        2.
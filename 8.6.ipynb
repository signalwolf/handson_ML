{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True):\n",
    "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID, fig_id + \".png\")\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format='png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000, 784) (10000, 784)\n",
      "(30596, 784) (5139, 784) (30596,) (5139,)\n",
      "(60000,) (5139,)\n",
      "(5000, 784) (25596, 784) (5000,) (25596,) (5139, 784) (5139,)\n"
     ]
    }
   ],
   "source": [
    "(X_data, y_data), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print (X_data.shape)\n",
    "\n",
    "# reduce the dimention of X_train, X_test\n",
    "def reduce_D (data):\n",
    "    return data.astype (np.float32).reshape (-1, 28 * 28) / 255.0\n",
    "X_data, X_test = reduce_D  (X_data), reduce_D (X_test)\n",
    "print (X_data.shape, X_test.shape)\n",
    "\n",
    "y_data = y_data.astype(np.int32)\n",
    "y_test = y_test.astype(np.int32)\n",
    "\n",
    "\n",
    "X_data_trimmed = X_data[y_data < 5]\n",
    "y_data_trimmed = y_data [y_data < 5]\n",
    "\n",
    "X_test = X_test [y_test < 5]\n",
    "y_test = y_test [y_test < 5]\n",
    "\n",
    "print (X_data_trimmed.shape, X_test.shape, y_data_trimmed.shape, y_test.shape)\n",
    "\n",
    "# Check Y :\n",
    "# print (y_data.shape)\n",
    "# def y_preprocess (data):\n",
    "#     return data.astype (np.int32).reshape (data.shape[0], 1)\n",
    "# y_data, y_test = y_preprocess (y_data), y_preprocess (y_test)\n",
    "print (y_data.shape, y_test.shape)\n",
    "\n",
    "# split the train and validation data:\n",
    "X_validation, y_validation = X_data_trimmed[:5000], y_data_trimmed[:5000]\n",
    "X_train, y_train = X_data_trimmed[5000:], y_data_trimmed[5000:]\n",
    "\n",
    "print (X_validation.shape, X_train.shape, y_validation.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "N_feature = X_test.shape[1]\n",
    "n_layers = 5\n",
    "n_neurons = 100\n",
    "learning_rate = 0.01\n",
    "n_output = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder (tf.float32, shape = (None, N_feature), name = 'X')\n",
    "y = tf.placeholder (tf.int32, shape = (None), name = 'y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope ('DNN_chapter11_86'):\n",
    "    he_init = tf.contrib.layers.variance_scaling_initializer (seed = 1)\n",
    "    hidden1 = tf.layers.dense (X, n_neurons, activation = tf.nn.elu, kernel_initializer = he_init, name = 'Hidden1')\n",
    "    hidden2 = tf.layers.dense (hidden1, n_neurons, activation = tf.nn.elu, kernel_initializer = he_init, name = 'Hidden2')\n",
    "    hidden3 = tf.layers.dense (hidden2, n_neurons, activation = tf.nn.elu, kernel_initializer = he_init, name = 'Hidden3')\n",
    "    hidden4 = tf.layers.dense (hidden3, n_neurons, activation = tf.nn.elu, kernel_initializer = he_init, name = 'Hidden4')\n",
    "    hidden5 = tf.layers.dense (hidden4, n_neurons, activation = tf.nn.elu, kernel_initializer = he_init, name = 'Hidden5')\n",
    "    y_predit = tf.layers.dense (hidden5, n_output, kernel_initializer = he_init, name = 'Output')\n",
    "    y_proba = tf.nn.softmax (y_predit, name = \"y_predit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope ('loss'):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y, logits=y_predit)\n",
    "    loss = tf.reduce_mean(xentropy, name=\"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"train\"):\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "    training_op = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(y_predit, y, 1)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver ()\n",
    "graph_\n",
    "save_path = r\"C:\\Users\\asiaynrf\\Desktop\\fun\\handson_ML\\model_saver\"\n",
    "n_steps = 20\n",
    "batch_size = 32\n",
    "data_size = X_train.shape[0]\n",
    "n_batch = int (np.ceil (data_size / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At step  0 the train_score is  1.0 the validation score is  0.9646 this cost 2.168649435043335\n",
      "At step  1 the train_score is  1.0 the validation score is  0.9722 this cost 2.1577701568603516\n",
      "At step  2 the train_score is  1.0 the validation score is  0.9758 this cost 2.3181517124176025\n",
      "At step  3 the train_score is  1.0 the validation score is  0.9778 this cost 2.2239668369293213\n",
      "At step  4 the train_score is  1.0 the validation score is  0.9788 this cost 2.273341178894043\n",
      "At step  5 the train_score is  1.0 the validation score is  0.9794 this cost 2.2438929080963135\n",
      "At step  6 the train_score is  1.0 the validation score is  0.9804 this cost 2.20210862159729\n",
      "At step  7 the train_score is  1.0 the validation score is  0.9814 this cost 2.241654396057129\n",
      "At step  8 the train_score is  1.0 the validation score is  0.9816 this cost 2.2515370845794678\n",
      "At step  9 the train_score is  1.0 the validation score is  0.9826 this cost 2.2176175117492676\n",
      "At step  10 the train_score is  1.0 the validation score is  0.9832 this cost 2.1987366676330566\n",
      "At step  11 the train_score is  1.0 the validation score is  0.9836 this cost 2.2650184631347656\n",
      "At step  12 the train_score is  1.0 the validation score is  0.9844 this cost 2.262749433517456\n",
      "At step  13 the train_score is  1.0 the validation score is  0.9844 this cost 2.2277462482452393\n",
      "At step  14 the train_score is  1.0 the validation score is  0.9846 this cost 2.3044848442077637\n",
      "At step  15 the train_score is  1.0 the validation score is  0.9854 this cost 2.1794042587280273\n",
      "At step  16 the train_score is  1.0 the validation score is  0.9856 this cost 2.366654634475708\n",
      "At step  17 the train_score is  1.0 the validation score is  0.9858 this cost 2.172450304031372\n",
      "At step  18 the train_score is  1.0 the validation score is  0.9858 this cost 2.1702966690063477\n",
      "At step  19 the train_score is  1.0 the validation score is  0.986 this cost 2.161510467529297\n",
      "Run 20 steps total process time is 50.06585431098938\n",
      "the test set accuracy is 0.99046504\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "with tf.Session() as sess:\n",
    "    init.run()\n",
    "    total_start_time = time.time()\n",
    "    for step in range (n_steps):\n",
    "        start_time = time.time ()\n",
    "        for i_batch in range (n_batch):\n",
    "            start = i_batch * batch_size\n",
    "            if i_batch != n_batch - 1:\n",
    "                end = start + batch_size\n",
    "            else:\n",
    "                end = data_size\n",
    "            sess.run (training_op, feed_dict = {X: X_train[start: end], y: y_train[start: end]})\n",
    "        train_score = accuracy.eval (feed_dict = {X: X_train[start: end], y: y_train[start: end]})\n",
    "        validation_score = accuracy.eval (feed_dict = {X: X_validation, y:y_validation})\n",
    "        end_time = time.time ()\n",
    "        run_time = end_time - start_time\n",
    "        print ('At step ', step, 'the train_score is ', train_score, 'the validation score is ', validation_score, 'this cost', run_time)\n",
    "        saver.save (sess, save_path + '/curr_model.ckpt')\n",
    "    total_end_time = time.time ()\n",
    "    accuracy_val = accuracy.eval (feed_dict = {X: X_test, y: y_test})\n",
    "    print ('Run', n_steps,  'steps total process time is',  total_end_time - total_start_time)\n",
    "    print ('the test set accuracy is', accuracy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\asiaynrf\\Desktop\\fun\\handson_ML\\model_saver/curr_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "with tf.Session () as sess: \n",
    "    saver.restore (sess, save_path + '/curr_model.ckpt')\n",
    "    accuracy_test = accuracy.eval (feed_dict = {X: X_test, y: y_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99046504"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
